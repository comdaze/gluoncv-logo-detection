{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GluonCV on SageMaker demo\n",
    "\n",
    "Let's first import the necessary modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gluoncv\n",
      "  Using cached https://files.pythonhosted.org/packages/66/1e/e9096a9742764c9427bb7e408bc867b8761d9a2a830514f1997d1e51abaf/gluoncv-0.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluoncv) (1.1.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluoncv) (2.20.0)\n",
      "Collecting tqdm (from gluoncv)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/b0/6d63e33dbf5935dccd334ee2b83cc4d3828817de6faaa3a3f7f5b8cc5141/tqdm-4.40.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluoncv) (3.0.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluoncv) (1.14.6)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from gluoncv) (5.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests->gluoncv) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests->gluoncv) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests->gluoncv) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests->gluoncv) (2.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->gluoncv) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->gluoncv) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->gluoncv) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->gluoncv) (2.7.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->gluoncv) (39.1.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->gluoncv) (1.11.0)\n",
      "Installing collected packages: tqdm, gluoncv\n",
      "Successfully installed gluoncv-0.5.0 tqdm-4.40.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import boto3\n",
    "import json\n",
    "import mxnet as mx\n",
    "from gluoncv import model_zoo, data, utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection with a pre-trained SSD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we are going to perform inference on a GluonCV object detection model that has been deployed in Amazon SageMaker. We run this notebook on our laptop to capture image data from the webcam and to send it to the SageMaker endpoint. \n",
    "\n",
    "The endpoint is running the model `ssd_512_resnet50_v1_voc` which has the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file is not found. Downloading.\n",
      "Downloading /home/ec2-user/.mxnet/models/resnet50_v1-cc729d95.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1-cc729d95.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57421/57421 [00:01<00:00, 42389.02KB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (features): FeatureExpander(\n",
       "  \n",
       "  )\n",
       "  (class_predictors): HybridSequential(\n",
       "    (0): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (4): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (box_predictors): HybridSequential(\n",
       "    (0): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (4): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): ConvPredictor(\n",
       "      (predictor): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (anchor_generators): HybridSequential(\n",
       "    (0): SSDAnchorGenerator(\n",
       "    \n",
       "    )\n",
       "    (1): SSDAnchorGenerator(\n",
       "    \n",
       "    )\n",
       "    (2): SSDAnchorGenerator(\n",
       "    \n",
       "    )\n",
       "    (3): SSDAnchorGenerator(\n",
       "    \n",
       "    )\n",
       "    (4): SSDAnchorGenerator(\n",
       "    \n",
       "    )\n",
       "    (5): SSDAnchorGenerator(\n",
       "    \n",
       "    )\n",
       "  )\n",
       "  (bbox_decoder): NormalizedBoxCenterDecoder(\n",
       "  \n",
       "  )\n",
       "  (cls_decoder): MultiPerClassDecoder(\n",
       "  \n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = model_zoo.get_model('ssd_512_resnet50_v1_voc', pretrained=False)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step we assume that the AWS credentials have been set beforehand. If this is not the case, make sure to set the following environment variables in the commandline before starting this notebook: `AWS_ACCESS_KEY_ID` `AWS_SECRET_ACCESS_KEY` and `AWS_SESSION_TOKEN`.\n",
    "\n",
    "In the following lines of code, we list the endpoints that have been deployed in our account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'EndpointName': 'gluoncv-bcbs-logo-detection',\n",
       "  'EndpointArn': 'arn:aws:sagemaker:us-east-1:291790195320:endpoint/gluoncv-bcbs-logo-detection',\n",
       "  'CreationTime': datetime.datetime(2019, 12, 6, 19, 0, 55, 278000, tzinfo=tzlocal()),\n",
       "  'LastModifiedTime': datetime.datetime(2019, 12, 6, 19, 8, 14, 469000, tzinfo=tzlocal()),\n",
       "  'EndpointStatus': 'InService'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime= boto3.client('runtime.sagemaker')\n",
    "client = boto3.client('sagemaker')\n",
    "client.list_endpoints()['Endpoints']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained SSD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we get the endpoint that has been deployed under the name `gluoncv-pretrained-object-detection-ssd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint in  client.list_endpoints()['Endpoints']:\n",
    "    if endpoint[\"EndpointName\"] == \"gluoncv-bcbs-logo-detection\":\n",
    "        gluoncv_endpoint = endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we capture image data from the local webcam and send it to the endpoint. The endpoint will perform inference and return bounding boxes, class ids and confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    img = cv2.resize(frame, (512,512))\n",
    "    payload = json.dumps(img.tolist())\n",
    "    response = runtime.invoke_endpoint(EndpointName=gluoncv_endpoint['EndpointName'],\n",
    "                                       Body=payload)\n",
    "    response_body = response['Body']\n",
    "    result = json.loads(response_body.read().decode())\n",
    "    [class_IDs, scores, bounding_boxes] = result\n",
    "    \n",
    "    bounding_boxes, scores, class_IDs =  mx.nd.array(bounding_boxes), mx.nd.array(scores), mx.nd.array(class_IDs)\n",
    "    ax = utils.viz.cv_plot_bbox(img, bounding_boxes[0], scores[0], class_IDs[0], thresh=0.6, class_names=net.classes)\n",
    "    \n",
    "    cv2.imshow(\"image\", img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Logo detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have deployed the GluonCV object detection model before in SageMaker under the name `gluoncv-demo-object-detection`. Now we retrieve this endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint in  client.list_endpoints()['Endpoints']:\n",
    "    if endpoint[\"EndpointName\"] == \"gluoncv-bcbs-logo-detection\":\n",
    "        gluoncv_endpoint = endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code section, we retrieve frames from the webcam and send it to the SageMaker endpoint. We first have to convert the data into JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VideoCapture 0x7f771aa3f6f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/feedstock_root/build_artefacts/opencv_1520639543262/work/opencv-3.3.0/modules/imgproc/src/imgwarp.cpp:3483: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-09e1d0ab686a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     response = runtime.invoke_endpoint(EndpointName=gluoncv_endpoint['EndpointName'],\n",
      "\u001b[0;31merror\u001b[0m: /feedstock_root/build_artefacts/opencv_1520639543262/work/opencv-3.3.0/modules/imgproc/src/imgwarp.cpp:3483: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    img = cv2.resize(frame, (512,512))\n",
    "    payload = json.dumps(img.tolist())\n",
    "    response = runtime.invoke_endpoint(EndpointName=gluoncv_endpoint['EndpointName'],\n",
    "                                       Body=payload)\n",
    "    response_body = response['Body']\n",
    "    result = json.loads(response_body.read().decode())\n",
    "    [class_IDs, scores, bounding_boxes] = result\n",
    "    \n",
    "    bounding_boxes, scores, class_IDs =  mx.nd.array(bounding_boxes), mx.nd.array(scores), mx.nd.array(class_IDs)\n",
    "    ax = utils.viz.cv_plot_bbox(img, bounding_boxes[0], scores[0], class_IDs[0], thresh=0.6, class_names=[\"AWS\"])\n",
    "    \n",
    "    cv2.imshow(\"image\", img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
